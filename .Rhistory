drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
apple.PCA <- PCA(apple, ncp=4, quali.sup=c(8),graph=FALSE)
par(mar = c(2.6, 4.1, 1.1, 2.1))
ggplot2::ggplot(cbind.data.frame(x=1:nrow(apple.PCA$eig),y=apple.PCA$eig[,2])) + ggplot2::aes(x=x, y=y)+ ggplot2::geom_col(fill="blue") + ggplot2::xlab("Dimension") + ggplot2::ylab("Percentage of variance") + ggplot2::ggtitle("Decomposition of the total inertia") + ggplot2::theme_light() + ggplot2::theme(plot.title = ggplot2::element_text(hjust =0.5)) + ggplot2::scale_x_continuous(breaks=1:nrow(apple.PCA$eig))
correlation_matrix <- cor(apple[,0:7])
ggcorrplot(correlation_matrix, type = "lower", lab = TRUE)
# Extract the eigenvalues from the PCA object
eigenvalues <- apple.PCA$eig
# Create a table from the eigenvalues
eigenvalue_table <- as.data.frame(eigenvalues)
knitr::kable(eigenvalue_table)
plot.PCA(apple.PCA, axes = c(1,2), choix='var')
plot.PCA(apple.PCA, axes = c(1,2), invisible=c('quali','ind.sup'), habillage = 8, label = "none", palette = palette(c("indianred2", "green4")), select = "cos2 0.25", cex=0.6, cex.main=0.6, cex.axis=0.6)
plot.PCA(apple.PCA, axes = c(1,3), choix='var')
plot.PCA(apple.PCA, axes = c(1,3), invisible=c('quali','ind.sup'), habillage = 8, label = "none", palette = palette(c("indianred2", "green4")), select = "cos2 0.25", cex=0.6, cex.main=0.6, cex.axis=0.6)
plot.PCA(apple.PCA, axes = c(1,4), choix='var')
plot.PCA(apple.PCA, axes = c(1,4), invisible=c('quali','ind.sup'), habillage = 8, label = "none", palette = palette(c("indianred2", "green4")), select = "cos2 0.25", cex=0.6, cex.main=0.6, cex.axis=0.6)
apple_pca_alt <- psych::principal(apple[0:7], rotate = "none", nfactors=4)
cor.plot(apple_pca_alt, main = "Variable Correlations with PCs")
## PCA
library(Factoshiny)
library(tidyverse)
library(corrr)
library(ggcorrplot)
library(factoextra)
library(psych)
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
apple.PCA <- PCA(apple, ncp=4, quali.sup=c(8),graph=FALSE)
par(mar = c(2.6, 4.1, 1.1, 2.1))
ggplot2::ggplot(cbind.data.frame(x=1:nrow(apple.PCA$eig),y=apple.PCA$eig[,2])) + ggplot2::aes(x=x, y=y)+ ggplot2::geom_col(fill="blue") + ggplot2::xlab("Dimension") + ggplot2::ylab("Percentage of variance") + ggplot2::ggtitle("Decomposition of the total inertia") + ggplot2::theme_light() + ggplot2::theme(plot.title = ggplot2::element_text(hjust =0.5)) + ggplot2::scale_x_continuous(breaks=1:nrow(apple.PCA$eig))
correlation_matrix <- cor(apple[,0:7])
ggcorrplot(correlation_matrix, type = "lower", lab = TRUE)
# Extract the eigenvalues from the PCA object
eigenvalues <- apple.PCA$eig
# Create a table from the eigenvalues
eigenvalue_table <- as.data.frame(eigenvalues)
knitr::kable(eigenvalue_table)
plot.PCA(apple.PCA, axes = c(1,2), choix='var')
plot.PCA(apple.PCA, axes = c(1,2), invisible=c('quali','ind.sup'), habillage = 8, label = "none", palette = palette(c("indianred2", "green4")), select = "cos2 0.25", cex=0.6, cex.main=0.6, cex.axis=0.6)
plot.PCA(apple.PCA, axes = c(1,3), choix='var')
plot.PCA(apple.PCA, axes = c(1,3), invisible=c('quali','ind.sup'), habillage = 8, label = "none", palette = palette(c("indianred2", "green4")), select = "cos2 0.25", cex=0.6, cex.main=0.6, cex.axis=0.6)
plot.PCA(apple.PCA, axes = c(1,4), choix='var')
plot.PCA(apple.PCA, axes = c(1,4), invisible=c('quali','ind.sup'), habillage = 8, label = "none", palette = palette(c("indianred2", "green4")), select = "cos2 0.25", cex=0.6, cex.main=0.6, cex.axis=0.6)
apple_pca_alt <- psych::principal(apple[0:7], rotate = "none", nfactors=4)
cor.plot(apple_pca_alt, main = "Variable Correlations with PCs")
apple_pca_rotated <- psych::principal(apple[0:7], rotate="varimax", nfactors=4, scores=TRUE)
cor.plot(apple_pca_rotated, main = "Rotated Variable Correlations with PCs")
library(tidyverse)
library(ggplot2)
# load data
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
set.seed(123)
numapple <- apple[,which(names(apple) != "Quality")]
### 1. K-means
# 1.1. within cluster inertia
k_max <- 10 # number of means
j_max <- 50 # number of kmeans
tot_withinss <- rep(NA, j_max)
tot_withinss_mean <- rep(NA, k_max)
for (k in 1:k_max){
for (j in 1:j_max) {
res.kmeans <- kmeans(numapple, k, algorithm="MacQueen")
tot_withinss[j] <- res.kmeans$tot.withinss
}
tot_withinss_mean[k] <- mean(tot_withinss)
}
# plot inertia decay
x <- c(1:k_max)
ggplot(data.frame(x, tot_withinss_mean), aes(x, tot_withinss_mean)) +
geom_line(color = "black", size = 1.5) +
geom_point(color = "red", size = 3) +
labs(x = "Number of clusters", y = "Within Cluster Intertia", title = "K-means Within Cluster Inertia by group number") +
expand_limits(x=1,y=0) +
scale_x_continuous(breaks = seq(min(x), max(x), by = 1))
# 1.2 check difference to true classes
res.kmeans <- kmeans(numapple, 2, algorithm="MacQueen", iter.max = 50)
apple$k_clust <- res.kmeans$cluster
apple$dQuality <- ifelse(apple$Quality == "good", 1, 0)
# table for mean quality of clusters
print(
apple %>%
group_by(k_clust) %>%
summarize(
mean_quality = mean(dQuality),
n = n()
) %>%
round(2)
)
library(FactoMineR)
res.ahc <- HCPC(numapple, nb.clust=-1, kk=1000)
apple$h_clust <- as.integer(res.ahc$data.clust$clust)
print(
apple %>%
group_by(h_clust) %>%
summarize(mean_quality = mean(dQuality), n = n()) %>%
round(2)
)
print(
apple %>%
group_by(h_clust) %>%
summarize(
Mean_quality = mean(dQuality),
Size = mean(Size),
Weight = mean(Weight),
Sweetness = mean(Sweetness),
Crunchiness = mean(Crunchiness),
Juiciness = mean(Juiciness),
Ripeness = mean(Ripeness),
Acidity = mean(Acidity)
) %>%
round(2) %>%
column_to_rownames(var = "h_clust")
)
library(tidyverse)
library(MASS)
library(caret)
library(ROCR)
library(pROC)
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(apple$Quality, p = .8, list = FALSE)
df_training <- apple[trainIndex, ]
df_testing <- apple[-trainIndex, ]
fit <- lda(Quality ~ ., data=df_training)
fit # show results
plot(fit)
# Predict using the fitted model
predictions <- predict(fit, df_testing[,-8])
# Evaluate model performance
confusionMatrix <- table(Predicted = predictions$class, Actual = df_testing$Quality)
print(confusionMatrix)
# Calculate accuracy - corrected line
accuracy <- sum(diag(confusionMatrix)) / sum(confusionMatrix)
print(paste("Accuracy:", round(accuracy,2), '%'))
pred_probs <- predict(fit, df_training, type = "response")
pred <- prediction(pred_probs$posterior[,2], df_training$Quality)
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize = TRUE, main = "ROC Curve for Quality Prediction")
perf_auc <- performance(pred, measure = "auc")
auc_value <- perf_auc@y.values[[1]]
auc_value
# Librairies
library(readr)
library(dplyr)
library(rpart)
library(rpart.plot)
library(caret)
library("ROCR")
# Set path to files
# Our dataset
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
# After split datasets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(apple$Quality, p = .8, list = FALSE)
df_training <- apple[trainIndex, ]
df_testing <- apple[-trainIndex, ]
# Format of our dataframes
library(DT)
styled_dt <- function(df, n=5) {
DT::datatable(df,
extensions = 'Buttons',
rownames = FALSE,
class = 'dataTables_wrapper',
options = list(
scrollX = TRUE,
pageLength = n,
dom = 'Bfrtip',
buttons = c('copy', 'csv', 'excel')
))
}
# Import
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
# Modification of the order of the columns
apple <- apple %>%
dplyr::select(Quality, everything())
# Data table
#styled_dt(apple)
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(apple$Quality, p = .8, list = FALSE)
df_train <- apple[trainIndex, ]
df_test <- apple[-trainIndex, ]
# Specifiying the positive class
df_train$Quality <- factor(df_train$Quality, levels = c("bad", "good"))
# Creating the tree classification
appletree <- rpart(Quality ~ ., data=df_train, method = "class", parms = list(split='gini'))
# Plot of the tree
rpart.plot(appletree, extra = 101)
# Plot of the cp parameters
plotcp(appletree)
# Print cp appletree
printcp(appletree)
# Pruning
appletree_pruned <- prune(appletree, cp = 0.018)
# Plot
rpart.plot(appletree_pruned, extra = 101)
table(predict(appletree_pruned, df_train, type="class"),df_train$Quality)
# Confusion matrix
table(predict(appletree, df_train, type = 'class'), df_train$Quality)
df_train_pred <- predict(appletree, df_train, type = 'class')
df_train_value <- as.factor(df_train$Quality)
confusionMatrix(df_train_pred, df_train_value, positive = "good")
pred_proba <- prediction(predict(appletree,type="prob")[, 2],df_train$Quality)
plot(performance(pred_proba, "tpr", "fpr"),colorize=TRUE)
abline(0, 1, lty = 2)
# Confusion matrix
table(predict(appletree, df_test, type = "class"), df_test$Quality)
df_test_pred <- predict(appletree, df_test, type = 'class')
df_test_value <- as.factor(df_test$Quality)
confusionMatrix(df_test_pred, df_test_value, positive = "good")
# Librairies
library(Factoshiny)
library(tidyverse)
library(corrr)
library(ggcorrplot)
library(factoextra)
library(psych)
# Data import
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
# Split in training and testing data
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(apple$Quality, p = .8, list = FALSE)
df_train <- apple[trainIndex, ]
df_test <- apple[-trainIndex, ]
pred_proba2 <- prediction(predict(appletree, df_test, type="prob")[, 2],df_test$Quality)
plot(performance(pred_proba2, "tpr", "fpr"),colorize=TRUE)
abline(0, 1, lty = 2)
?rpart.plot
?createDataPartition
?rpart
?rpart.plot
```{r, fig.align='center'}
# Librairies
library(Factoshiny)
library(tidyverse)
library(corrr)
library(ggcorrplot)
library(factoextra)
library(psych)
library(caret)
library(rpart)
library(rpart.plot)
# Data import
apple <- read_csv("Dataset/apple_dataset.csv") %>%
dplyr::select(-A_id) %>%
drop_na() %>%
mutate(Acidity = as.numeric(Acidity),
across(where(is.numeric), ~ scale(.) %>% as.vector))
# Split in training and testing data
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(apple$Quality, p = .8, list = FALSE)
df_train <- apple[trainIndex, ]
df_test <- apple[-trainIndex, ]
fit$means # show results
knitr::kable(fit$means# show results)
knitr::kable(fit$means) # show results
fit$means %>% kable('Latex') # show results
fit$means %>% knitr::kable('Latex') # show results
fit$means %>% dplyr::kable('Latex') # show results
fit$means %>% knitr::kable('Latex') # show results
?lda
library(MASS)
?kable_Latex
?rotate_table
??rotate_table
?prediction
# Global dataset
airports_politics <- openxlsx::read.xlsx(xlsxFile="datasets/DATA_POLITICS.xlsx")
# Dataset for politics and airports
col_start <- which(names(airports_politics) == "2002-01")
col_end <- which(names(airports_politics) == "2023-09")
library(dplyr)
airports <- airports_politics %>% dplyr::select(1, col_start : col_end)
politics <- airports_politics %>% dplyr::select(1, (col_end+1):length(airports_politics))
# Dataset for each policy
#a
col_start_a <- which(names(airports_politics) == "2002-01.a")
col_end_a <- which(names(airports_politics) == "2023-09.a")
policy_a <- airports_politics %>% dplyr::select(1, col_start_a : col_end_a)
#b
col_start_b <- which(names(airports_politics) == "2002-01.b")
col_end_b <- which(names(airports_politics) == "2023-09.b")
policy_b <- airports_politics %>% dplyr::select(1, col_start_b : col_end_b)
#c
col_start_c <- which(names(airports_politics) == "2002-01.c")
col_end_c <- which(names(airports_politics) == "2023-09.c")
policy_c <- airports_politics %>% dplyr::select(1, col_start_c : col_end_c)
# Pivot
policy_a <- tidyr::pivot_longer(policy_a, cols = -c("Airport"), names_to = "Date", values_to = "Borders main EU period")
policy_b <- tidyr::pivot_longer(policy_b, cols = -c("Airport"), names_to = "Date", values_to = "Borders non-EU period")
policy_c <- tidyr::pivot_longer(policy_c, cols = -c("Airport"), names_to = "Date", values_to = "Negative tests period")
airports <- tidyr::pivot_longer(airports, cols = -c("Airport"), names_to = "Date", values_to = "Passenger")
# Formating date
policy_a$Date <- gsub("\\.a$", "", policy_a$Date)
policy_b$Date <- gsub("\\.b$", "", policy_b$Date)
policy_c$Date <- gsub("\\.c$", "", policy_c$Date)
# Merging
politics_formate <- merge(airports, policy_a, by = c("Airport", "Date"), all.x = TRUE)
politics_formate <- merge(politics_formate, policy_b, by = c("Airport", "Date"), all.x = TRUE)
politics_formate <- merge(politics_formate, policy_c, by = c("Airport", "Date"), all.x = TRUE)
# Date format
politics_formate$Date <- zoo::as.Date(paste0(politics_formate$Date, "-01"), format="%Y-%m-%d")
# Kopenhagen
kopen <- politics_formate %>% dplyr::filter(Airport == "KOBENHAVN/KASTRUP airport")
# Madrid
madrid <- politics_formate %>% dplyr::filter(Airport == "ADOLFO SUAREZ MADRID-BARAJAS airport")
# Oslo
oslo <- politics_formate %>% dplyr::filter(Airport == "OSLO/GARDERMOEN airport")
# Paris
paris <- politics_formate %>% dplyr::filter(Airport == "ADOLFO SUAREZ MADRID-BARAJAS airport")
# Roma
roma <- politics_formate %>% dplyr::filter(Airport == "ROMA/FIUMICINO airport")
styled_dt(kopen)
library(dplyr)
library(zoo)
library(xts)
library(tidyr)
library(magrittr)
library(ggplot2)
library(tseries)
library(forecast)
# Format of our dataframes
styled_dt <- function(df, n=5) {
DT::datatable(df,
extensions = 'Buttons',
rownames = FALSE,
class = 'dataTables_wrapper',
options = list(
scrollX = TRUE,
pageLength = n,
dom = 'Bfrtip',
buttons = c('copy', 'csv', 'excel')
))
}
# Global data
traffic <- openxlsx::read.xlsx(xlsxFile="datasets/data_airports_APP.xlsx")
# Simplified label
traffic <- traffic %>% dplyr::rename("Airport" = "REP_AIRP.(Labels)")
# Country
airports_names<- read.csv("datasets/airports_by_country.csv")
airports_names$Airport <- paste(airports_names$Airport, "airport", sep = " ")
airports_names <- airports_names %>% mutate(Country = ifelse(Country == "Chile", "Spain", Country))
# EU
eu_countries_2019 <- read.csv("datasets/eu_countries_2019.csv")
# Selection
names_col <- names(traffic)
selected_col <- c(names_col[1], names_col[50:length(names_col)])
traffic <- traffic %>% dplyr::select(all_of(selected_col))
# Merged
traffic_mg <- merge(traffic, airports_names, by = "Airport", all.x = TRUE)
airports_dupli <- duplicated(traffic_mg)
length(traffic_mg[airports_dupli,])
# Duplicates erase
traffic_mg <- unique(traffic_mg)
# Checking
airports_without_country <- traffic_mg[is.na(traffic_mg$Country), ]
styled_dt(airports_without_country, 5)
styled_dt(traffic_mg, 5)
# Modification
traffic_pivot <- tidyr::pivot_longer(traffic_mg, cols = -c("Airport", "Country"), names_to = "Date", values_to = "Passengers")
# Managing Nan
traffic_pivot$Passengers[traffic_pivot$Passengers == ":"] <- 0
# Numerical values
traffic_pivot$Passengers <- as.numeric(traffic_pivot$Passengers)
# Date
traffic_pivot$Date <- zoo::as.Date(paste0(traffic_pivot$Date, "-01"), format="%Y-%m-%d")
# Sum
traffic_sum <- traffic_pivot %>% group_by(Airport, Country) %>% summarise(sumPassengers = sum(Passengers))
# Selection
airports_best_ranked <- traffic_sum %>% group_by(Country) %>% slice_max(order_by = sumPassengers)
# Erase
airports_best_ranked <- airports_best_ranked %>% filter(sumPassengers != 0)
list_countries = c("Faroe Islands (Denmark)", "Fictional/Private", "French Guiana",
"Guadeloupe (France)", "Martinique (France)", "Mayotte (France)", "Reunion (France)",
"Saint Barthelemy (France)", "Saint Martin (France)", "Svalbard (Norway)", NA)
airports_best_ranked <- airports_best_ranked %>% filter(!(Country %in% list_countries))
# Final dataset
airports_final_list <- unique(airports_best_ranked$Airport)
traffic_checked <- traffic_pivot %>% filter(Airport %in% airports_final_list)
write.csv(traffic_checked, file = "datasets/data_airports_cleaned_APP.csv", row.names = FALSE, na = "NA")
styled_dt(traffic_checked)
# EU
eu_sum <- eu_countries_2019 %>% group_by(EU_2019) %>% count()
eu_sum <- eu_sum %>% mutate(EU_2019 = ifelse(EU_2019 == 1, "Member", "Non member"))
# Plot
ggplot(eu_sum, aes(x = EU_2019, y = n, fill = EU_2019)) +
geom_bar(stat = "identity") +
geom_text(aes(label = n), vjust = 3, colour = 'white', size = 4) +
labs(title = "Repartition of european countries", x = "", y = "Number of countries", fill = "European Union (2019)") +
theme_minimal()
ggplot2::ggplot(airports_best_ranked, aes(x = sumPassengers, y = reorder(Country, sumPassengers))) +
geom_bar(stat = "identity", fill = "green") +
labs(title = "Ranking of Countries based on their traffic",
x = "Total passengers carried",
y = "Country")
View(traffic_checked)
# List of the airports
airports_to_keep <- c("PARIS-CHARLES DE GAULLE", "ADOLFO SUAREZ MADRID-BARAJAS", "ROMA/FIUMICINO", "KOBENHAVN/KASTRUP", "OSLO/GARDERMOEN")
# Filter
filtered_traffic_checked <- traffic_checked %>%
dplyr::filter(Airport %in% airports_to_keep)
View(filtered_traffic_checked)
# List of the airports
airports_to_keep <- c("PARIS-CHARLES DE GAULLE airport", "ADOLFO SUAREZ MADRID-BARAJAS airport", "ROMA/FIUMICINO airport", "KOBENHAVN/KASTRUP airport", "OSLO/GARDERMOEN airport")
# Filter
filtered_traffic_checked <- traffic_checked %>%
dplyr::filter(Airport %in% airports_to_keep)
View(filtered_traffic_checked)
# Plot
ggplot2::ggplot(filtered_traffic_checked, aes(x = Date, y = Passengers, color = Country)) +
geom_line() +
theme_minimal() +
labs(title = "Monthly Passengers per Country", x = "Date", y = "Number of Passengers")
# Path to your .qmd file
qmd_file <- "airport-traffic.qmd"
# Destination for the .r file
r_file <- "airport-traffic.r"
# Read the lines of the .qmd file
lines <- readLines(qmd_file)
# Initialize a variable to keep track of whether you're inside a code chunk
in_chunk <- FALSE
# Initialize a vector to hold the lines of R code
r_code <- c()
# Loop through each line of the .qmd file
for (line in lines) {
if (grepl("^\\{r.*\\}", line)) {
# Starting an R code chunk
in_chunk <- TRUE
} else if (grepl("^$", line) && in_chunk) {
# Ending an R code chunk
in_chunk <- FALSE
} else if (in_chunk) {
# Within an R code chunk, add the line to the r_code vector
r_code <- c(r_code, line)
}
}
# Write the extracted R code to an .r file
writeLines(r_code, r_file)
# Chemin vers ton fichier Quarto
quarto_file_path <- "/Users/nathanpizzetta/Documents/TSE/Cours/M1/Applied econometrics/Code/airport-traffic.qmd"
# Chemin du fichier R de sortie
output_r_file_path <- "/Users/nathanpizzetta/Documents/TSE/Cours/M1/Applied econometrics/Code/airport-traffic.R"
# Lire le contenu du fichier Quarto
quarto_content <- readLines(quarto_file_path)
# Initialiser une variable pour stocker le code R
r_code <- ""
# Extraire les chunks de code R
for (line in quarto_content) {
if (grepl("^```{r.*}", line)) { # Début d'un chunk R
r_code <- paste(r_code, line, sep="\n")
next
}
if (grepl("^```", line) && nchar(r_code) > 0) { # Fin d'un chunk R
r_code <- paste(r_code, line, sep="\n")
r_code <- paste(r_code, "\n", sep="") # Ajouter une ligne vide après chaque chunk pour la lisibilité
next
}
if (nchar(r_code) > 0 && !grepl("^```", line)) { # Code R à l'intérieur d'un chunk
r_code <- paste(r_code, line, sep="\n")
}
}
# Path to your .qmd file
qmd_file <- "/Users/nathanpizzetta/Documents/TSE/Cours/M1/Applied econometrics/Code/airport-traffic.qmd"
# Destination for the .r file
r_file <- "airport-traffic.r"
# Read the lines of the .qmd file
lines <- readLines(qmd_file)
# Initialize a variable to keep track of whether you're inside a code chunk
in_chunk <- FALSE
# Initialize a vector to hold the lines of R code
r_code <- c()
# Loop through each line of the .qmd file
for (line in lines) {
if (grepl("^\\{r.*\\}", line)) {
# Starting an R code chunk
in_chunk <- TRUE
} else if (grepl("^$", line) && in_chunk) {
# Ending an R code chunk
in_chunk <- FALSE
} else if (in_chunk) {
# Within an R code chunk, add the line to the r_code vector
r_code <- c(r_code, line)
}
}
# Write the extracted R code to an .r file
writeLines(r_code, r_file)
0.7523/0.1809
